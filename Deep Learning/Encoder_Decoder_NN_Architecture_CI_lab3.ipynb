{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1\n",
        "\n",
        "Extract a subset of traning samples from the MNIST handwriten signatures. Create a small convolution neural network with two convolution layers, two pool layers, flatten, dense layer and softmax layer to classify the images. Find out classification error for learning set and testing set.\n",
        "\n"
      ],
      "metadata": {
        "id": "uGHCiLHJ6GWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Extract a subset of training samples (for example, first 1000 samples)\n",
        "train_images = train_images[:1000]\n",
        "train_labels = train_labels[:1000]\n",
        "\n",
        "# Preprocess the data\n",
        "train_images = train_images.reshape((train_images.shape[0], 28, 28, 1))\n",
        "train_images = train_images.astype('float32') / 255\n",
        "\n",
        "test_images = test_images.reshape((test_images.shape[0], 28, 28, 1))\n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "train_labels = tf.keras.utils.to_categorical(train_labels, 10)\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels, 10)\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_images, train_labels, epochs=20, batch_size=64, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model on the training set\n",
        "train_loss, train_acc = model.evaluate(train_images, train_labels)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "\n",
        "print(f'Training accuracy: {train_acc*100:.2f}%')\n",
        "print(f'Testing accuracy: {test_acc*100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fG9GUAp9T6F",
        "outputId": "971c8e78-73ec-4237-ba9c-0b80e6cf4cef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/20\n",
            "13/13 [==============================] - 5s 148ms/step - loss: 2.1080 - accuracy: 0.3638 - val_loss: 1.7415 - val_accuracy: 0.6850\n",
            "Epoch 2/20\n",
            "13/13 [==============================] - 2s 186ms/step - loss: 1.2412 - accuracy: 0.7312 - val_loss: 0.8453 - val_accuracy: 0.7600\n",
            "Epoch 3/20\n",
            "13/13 [==============================] - 3s 194ms/step - loss: 0.5545 - accuracy: 0.8425 - val_loss: 0.6130 - val_accuracy: 0.8150\n",
            "Epoch 4/20\n",
            "13/13 [==============================] - 2s 143ms/step - loss: 0.3571 - accuracy: 0.8838 - val_loss: 0.4267 - val_accuracy: 0.8800\n",
            "Epoch 5/20\n",
            "13/13 [==============================] - 2s 119ms/step - loss: 0.2746 - accuracy: 0.9200 - val_loss: 0.4160 - val_accuracy: 0.8950\n",
            "Epoch 6/20\n",
            "13/13 [==============================] - 1s 107ms/step - loss: 0.2074 - accuracy: 0.9513 - val_loss: 0.3551 - val_accuracy: 0.8950\n",
            "Epoch 7/20\n",
            "13/13 [==============================] - 1s 112ms/step - loss: 0.1581 - accuracy: 0.9588 - val_loss: 0.3605 - val_accuracy: 0.9050\n",
            "Epoch 8/20\n",
            "13/13 [==============================] - 2s 123ms/step - loss: 0.1186 - accuracy: 0.9663 - val_loss: 0.3538 - val_accuracy: 0.9150\n",
            "Epoch 9/20\n",
            "13/13 [==============================] - 2s 119ms/step - loss: 0.0925 - accuracy: 0.9787 - val_loss: 0.3254 - val_accuracy: 0.9100\n",
            "Epoch 10/20\n",
            "13/13 [==============================] - 2s 127ms/step - loss: 0.0715 - accuracy: 0.9812 - val_loss: 0.3224 - val_accuracy: 0.9150\n",
            "Epoch 11/20\n",
            "13/13 [==============================] - 2s 134ms/step - loss: 0.0691 - accuracy: 0.9812 - val_loss: 0.3270 - val_accuracy: 0.9200\n",
            "Epoch 12/20\n",
            "13/13 [==============================] - 1s 105ms/step - loss: 0.0646 - accuracy: 0.9812 - val_loss: 0.3709 - val_accuracy: 0.9150\n",
            "Epoch 13/20\n",
            "13/13 [==============================] - 1s 98ms/step - loss: 0.0443 - accuracy: 0.9900 - val_loss: 0.3909 - val_accuracy: 0.9100\n",
            "Epoch 14/20\n",
            "13/13 [==============================] - 1s 60ms/step - loss: 0.0411 - accuracy: 0.9900 - val_loss: 0.3491 - val_accuracy: 0.9150\n",
            "Epoch 15/20\n",
            "13/13 [==============================] - 1s 60ms/step - loss: 0.0294 - accuracy: 0.9950 - val_loss: 0.3764 - val_accuracy: 0.9050\n",
            "Epoch 16/20\n",
            "13/13 [==============================] - 1s 59ms/step - loss: 0.0177 - accuracy: 0.9975 - val_loss: 0.3583 - val_accuracy: 0.9200\n",
            "Epoch 17/20\n",
            "13/13 [==============================] - 1s 60ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.3442 - val_accuracy: 0.9150\n",
            "Epoch 18/20\n",
            "13/13 [==============================] - 1s 60ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.3752 - val_accuracy: 0.9150\n",
            "Epoch 19/20\n",
            "13/13 [==============================] - 1s 61ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.3583 - val_accuracy: 0.9250\n",
            "Epoch 20/20\n",
            "13/13 [==============================] - 1s 59ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.3940 - val_accuracy: 0.9150\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0833 - accuracy: 0.9830\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.2412 - accuracy: 0.9341\n",
            "Training accuracy: 98.30%\n",
            "Testing accuracy: 93.41%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate classification error for learning set\n",
        "train_error = 1 - train_acc\n",
        "\n",
        "# Calculate classification error for testing set\n",
        "test_error = 1 - test_acc\n",
        "\n",
        "print(f'Classification error for learning set: {train_error*100:.2f}%')\n",
        "print(f'Classification error for testing set: {test_error*100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V08Tncs99x1d",
        "outputId": "0948b85f-b061-4b35-8064-ae4bfc2093d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification error for learning set: 1.70%\n",
            "Classification error for testing set: 6.59%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "# Assuming 'model' is the name of your Sequential model\n",
        "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n"
      ],
      "metadata": {
        "id": "xC7DG8Ag7i0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQPdK-QLnUGp"
      },
      "source": [
        "# Task 2\n",
        "\n",
        "Create an autoencoder for MNIST fashion dataset. The input and the output is the same image of a number 28x28 pixels.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhlcVaeTfczu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "df7e4c04-0ee7-4453-831e-70a9401d8ffe"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "(x_train, _), (x_test, _) = fashion_mnist.load_data()\n",
        "\n",
        "# Normalize pixel values between 0 and 1\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Flatten the images\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "\n",
        "# Define the autoencoder architecture\n",
        "input_img = Input(shape=(784,))\n",
        "encoded = Dense(128, activation='relu')(input_img)\n",
        "encoded = Dense(64, activation='relu')(encoded)\n",
        "encoded = Dense(32, activation='relu')(encoded)\n",
        "\n",
        "decoded = Dense(64, activation='relu')(encoded)\n",
        "decoded = Dense(128, activation='relu')(decoded)\n",
        "decoded = Dense(784, activation='sigmoid')(decoded)\n",
        "\n",
        "# Create the autoencoder model\n",
        "autoencoder = Model(input_img, decoded)\n",
        "\n",
        "# Compile the autoencoder model\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Train the autoencoder\n",
        "autoencoder.fit(x_train, x_train, epochs=50, batch_size=256, shuffle=True, validation_data=(x_test, x_test))\n",
        "\n",
        "# Encode and decode some images\n",
        "encoded_imgs = autoencoder.predict(x_test)\n",
        "\n",
        "# Plot original and reconstructed images\n",
        "n = 10  # number of images to display\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # Display original images\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # Display reconstructed images\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(encoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n",
            "Epoch 1/50\n",
            "235/235 [==============================] - 11s 30ms/step - loss: 0.3797 - val_loss: 0.3198\n",
            "Epoch 2/50\n",
            "235/235 [==============================] - 6s 24ms/step - loss: 0.3106 - val_loss: 0.3070\n",
            "Epoch 3/50\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.3019 - val_loss: 0.3012\n",
            "Epoch 4/50\n",
            "235/235 [==============================] - 5s 21ms/step - loss: 0.2971 - val_loss: 0.2974\n",
            "Epoch 5/50\n",
            "235/235 [==============================] - 5s 23ms/step - loss: 0.2941 - val_loss: 0.2949\n",
            "Epoch 6/50\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.2918 - val_loss: 0.2932\n",
            "Epoch 7/50\n",
            "235/235 [==============================] - 5s 21ms/step - loss: 0.2899 - val_loss: 0.2915\n",
            "Epoch 8/50\n",
            "235/235 [==============================] - 5s 23ms/step - loss: 0.2886 - val_loss: 0.2900\n",
            "Epoch 9/50\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.2873 - val_loss: 0.2889\n",
            "Epoch 10/50\n",
            "235/235 [==============================] - 5s 21ms/step - loss: 0.2862 - val_loss: 0.2880\n",
            "Epoch 11/50\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.2853 - val_loss: 0.2869\n",
            "Epoch 12/50\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.2844 - val_loss: 0.2862\n",
            "Epoch 13/50\n",
            "235/235 [==============================] - 6s 24ms/step - loss: 0.2836 - val_loss: 0.2855\n",
            "Epoch 14/50\n",
            "235/235 [==============================] - 5s 22ms/step - loss: 0.2829 - val_loss: 0.2846\n",
            "Epoch 15/50\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.2822 - val_loss: 0.2846\n",
            "Epoch 16/50\n",
            "235/235 [==============================] - 5s 23ms/step - loss: 0.2816 - val_loss: 0.2836\n",
            "Epoch 17/50\n",
            "235/235 [==============================] - 5s 22ms/step - loss: 0.2811 - val_loss: 0.2834\n",
            "Epoch 18/50\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.2806 - val_loss: 0.2831\n",
            "Epoch 19/50\n",
            "235/235 [==============================] - 5s 23ms/step - loss: 0.2803 - val_loss: 0.2831\n",
            "Epoch 20/50\n",
            "235/235 [==============================] - 5s 21ms/step - loss: 0.2798 - val_loss: 0.2818\n",
            "Epoch 21/50\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.2794 - val_loss: 0.2816\n",
            "Epoch 22/50\n",
            "235/235 [==============================] - 6s 23ms/step - loss: 0.2790 - val_loss: 0.2814\n",
            "Epoch 23/50\n",
            "235/235 [==============================] - 5s 22ms/step - loss: 0.2787 - val_loss: 0.2811\n",
            "Epoch 24/50\n",
            "235/235 [==============================] - 4s 19ms/step - loss: 0.2784 - val_loss: 0.2810\n",
            "Epoch 25/50\n",
            "235/235 [==============================] - 6s 24ms/step - loss: 0.2780 - val_loss: 0.2803\n",
            "Epoch 26/50\n",
            "235/235 [==============================] - 5s 20ms/step - loss: 0.2778 - val_loss: 0.2805\n",
            "Epoch 27/50\n",
            "235/235 [==============================] - 4s 19ms/step - loss: 0.2775 - val_loss: 0.2797\n",
            "Epoch 28/50\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.2773 - val_loss: 0.2798\n",
            "Epoch 29/50\n",
            "235/235 [==============================] - 5s 20ms/step - loss: 0.2771 - val_loss: 0.2792\n",
            "Epoch 30/50\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.2768 - val_loss: 0.2790\n",
            "Epoch 31/50\n",
            "235/235 [==============================] - 6s 24ms/step - loss: 0.2766 - val_loss: 0.2788\n",
            "Epoch 32/50\n",
            "235/235 [==============================] - 5s 20ms/step - loss: 0.2764 - val_loss: 0.2787\n",
            "Epoch 33/50\n",
            "235/235 [==============================] - 5s 20ms/step - loss: 0.2762 - val_loss: 0.2787\n",
            "Epoch 34/50\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.2760 - val_loss: 0.2784\n",
            "Epoch 35/50\n",
            "235/235 [==============================] - 4s 19ms/step - loss: 0.2759 - val_loss: 0.2782\n",
            "Epoch 36/50\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.2757 - val_loss: 0.2781\n",
            "Epoch 37/50\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.2756 - val_loss: 0.2778\n",
            "Epoch 38/50\n",
            "235/235 [==============================] - 5s 19ms/step - loss: 0.2754 - val_loss: 0.2778\n",
            "Epoch 39/50\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.2752 - val_loss: 0.2776\n",
            "Epoch 40/50\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.2751 - val_loss: 0.2774\n",
            "Epoch 41/50\n",
            "235/235 [==============================] - 5s 19ms/step - loss: 0.2750 - val_loss: 0.2776\n",
            "Epoch 42/50\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.2748 - val_loss: 0.2771\n",
            "Epoch 43/50\n",
            "235/235 [==============================] - 5s 23ms/step - loss: 0.2746 - val_loss: 0.2771\n",
            "Epoch 44/50\n",
            "235/235 [==============================] - 5s 20ms/step - loss: 0.2745 - val_loss: 0.2767\n",
            "Epoch 45/50\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.2745 - val_loss: 0.2772\n",
            "Epoch 46/50\n",
            "235/235 [==============================] - 5s 22ms/step - loss: 0.2743 - val_loss: 0.2766\n",
            "Epoch 47/50\n",
            "235/235 [==============================] - 5s 22ms/step - loss: 0.2742 - val_loss: 0.2767\n",
            "Epoch 48/50\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.2741 - val_loss: 0.2766\n",
            "Epoch 49/50\n",
            "235/235 [==============================] - 5s 22ms/step - loss: 0.2740 - val_loss: 0.2765\n",
            "Epoch 50/50\n",
            "235/235 [==============================] - 5s 22ms/step - loss: 0.2739 - val_loss: 0.2765\n",
            "313/313 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x400 with 20 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnEG4QgNnTHP"
      },
      "source": [
        "import random as rnd\n",
        "\n",
        "t_x = []\n",
        "t_y = []\n",
        "sz = len(train_images)\n",
        "for i in range(20):\n",
        "   idx = rnd.randint(0,sz-1)\n",
        "   for c in range(10):\n",
        "     while c not in train_labels[idx]:\n",
        "       idx = rnd.randint(0,sz-1)\n",
        "     t_x += [np.ndarray.flatten(train_images[idx])]\n",
        "     t_y += [train_labels[idx]]\n",
        "\n",
        "t_x = np.array(t_x, dtype=np.float32)/255.0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "import random as rnd\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# Create a random subset of the dataset\n",
        "t_x = []\n",
        "t_y = []\n",
        "sz = len(train_images)\n",
        "for i in range(20):\n",
        "    idx = rnd.randint(0, sz - 1)\n",
        "    for c in range(10):\n",
        "        while train_labels[idx] != c:\n",
        "            idx = rnd.randint(0, sz - 1)\n",
        "        t_x.append(np.ndarray.flatten(train_images[idx]))\n",
        "        t_y.append(train_labels[idx])\n",
        "\n",
        "t_x = np.array(t_x, dtype=np.float32) / 255.0\n",
        "\n",
        "# Flatten the images\n",
        "t_x = t_x.reshape((len(t_x), np.prod(t_x.shape[1:])))\n",
        "\n",
        "# autoencoder architecture\n",
        "input_img = Input(shape=(784,))\n",
        "encoded = Dense(128, activation='relu')(input_img)\n",
        "encoded = Dense(64, activation='relu')(encoded)\n",
        "encoded = Dense(32, activation='relu')(encoded)\n",
        "\n",
        "decoded = Dense(64, activation='relu')(encoded)\n",
        "decoded = Dense(128, activation='relu')(decoded)\n",
        "decoded = Dense(784, activation='sigmoid')(decoded)\n",
        "\n",
        "# autoencoder model\n",
        "autoencoder = Model(input_img, decoded)\n",
        "\n",
        "# Compile\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Train\n",
        "autoencoder.fit(t_x, t_x, epochs=50, batch_size=4, shuffle=True)\n",
        "\n",
        "# Encode and decode the subset images\n",
        "decoded_imgs = autoencoder.predict(t_x)\n",
        "\n",
        "# Plot original and reconstructed images\n",
        "n = len(t_x)\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # Display original images\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(t_x[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # Display reconstructed images\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3ZE88gJPD2n-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "import random as rnd\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# Create a random subset of the dataset\n",
        "t_x = []\n",
        "t_y = []\n",
        "sz = len(train_images)\n",
        "for i in range(20):\n",
        "    idx = rnd.randint(0, sz - 1)\n",
        "    for c in range(10):\n",
        "        while train_labels[idx] != c:\n",
        "            idx = rnd.randint(0, sz - 1)\n",
        "        t_x.append(np.ndarray.flatten(train_images[idx]))\n",
        "        t_y.append(train_labels[idx])\n",
        "\n",
        "t_x = np.array(t_x, dtype=np.float32) / 255.0\n",
        "\n",
        "\n",
        "t_x = t_x.reshape((len(t_x), np.prod(t_x.shape[1:])))\n",
        "\n",
        "# autoencoder architecture\n",
        "input_img = Input(shape=(784,))\n",
        "encoded = Dense(128, activation='relu')(input_img)\n",
        "encoded = Dense(64, activation='relu')(encoded)\n",
        "encoded = Dense(32, activation='relu')(encoded)\n",
        "\n",
        "decoded = Dense(64, activation='relu')(encoded)\n",
        "decoded = Dense(128, activation='relu')(decoded)\n",
        "decoded = Dense(784, activation='sigmoid')(decoded)\n",
        "\n",
        "# autoencoder model\n",
        "autoencoder = Model(input_img, decoded)\n",
        "\n",
        "# Compile\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Train\n",
        "autoencoder.fit(t_x, t_x, epochs=50, batch_size=4, shuffle=True)\n",
        "\n",
        "# Encode and decode the subset images\n",
        "decoded_imgs = autoencoder.predict(t_x)\n",
        "\n",
        "# Separate visualizations for original, reconstructed, and encoded images\n",
        "n = len(t_x)\n",
        "plt.figure(figsize=(20, 6))\n",
        "\n",
        "# Plot original images\n",
        "for i in range(n):\n",
        "    ax = plt.subplot(3, n, i + 1)\n",
        "    plt.imshow(t_x[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "plt.title('Original Images')\n",
        "\n",
        "# Plot reconstructed images\n",
        "for i in range(n):\n",
        "    ax = plt.subplot(3, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "plt.title('Reconstructed Images')\n",
        "\n",
        "# Plot encoded representations\n",
        "encoder_model = Model(inputs=input_img, outputs=encoded)\n",
        "encoded_imgs = encoder_model.predict(t_x)\n",
        "\n",
        "for i in range(n):\n",
        "    ax = plt.subplot(3, n, i + 1 + 2 * n)\n",
        "    plt.imshow(encoded_imgs[i].reshape(8, 4))  # 32-dimensional encoded representation\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "plt.title('Encoded Representations')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "_qtmDNraHUic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vfUQsjVw89j"
      },
      "source": [
        "\n",
        "## Subtask 1\n",
        "\n",
        " Use two dense layers (hidden and output). Hidden layer with 2 neurons, output layer with 784 neurons. Plot the response of hidden neurons in scatter plot, number categories distinquish by colors.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewO09nXcxN2i"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "import random as rnd\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# Load the MNIST Fashion dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# Create a random subset of the dataset\n",
        "t_x = []\n",
        "t_y = []\n",
        "sz = len(train_images)\n",
        "for i in range(20):\n",
        "    idx = rnd.randint(0, sz - 1)\n",
        "    for c in range(10):\n",
        "        while train_labels[idx] != c:\n",
        "            idx = rnd.randint(0, sz - 1)\n",
        "        t_x.append(np.ndarray.flatten(train_images[idx]))\n",
        "        t_y.append(train_labels[idx])\n",
        "\n",
        "t_x = np.array(t_x, dtype=np.float32) / 255.0\n",
        "\n",
        "# Flatten the images\n",
        "t_x = t_x.reshape((len(t_x), np.prod(t_x.shape[1:])))\n",
        "\n",
        "# Define the autoencoder architecture with 2 neurons in the hidden layer\n",
        "input_img = Input(shape=(784,))\n",
        "encoded = Dense(2, activation='relu')(input_img)\n",
        "decoded = Dense(784, activation='sigmoid')(encoded)\n",
        "\n",
        "# Create the autoencoder model\n",
        "autoencoder = Model(input_img, decoded)\n",
        "\n",
        "# Compile the autoencoder model\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Train the autoencoder\n",
        "autoencoder.fit(t_x, t_x, epochs=50, batch_size=4, shuffle=True)\n",
        "\n",
        "# Extract the responses of the hidden layer\n",
        "encoder_model = Model(inputs=input_img, outputs=encoded)\n",
        "encoded_imgs = encoder_model.predict(t_x)\n",
        "\n",
        "# Plot the response of hidden neurons in a scatter plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "scatter = plt.scatter(encoded_imgs[:, 0], encoded_imgs[:, 1], c=t_y, cmap='tab10')\n",
        "plt.colorbar(scatter, label='Number Category')\n",
        "plt.title('Hidden Neuron Responses')\n",
        "plt.xlabel('Hidden Neuron 1')\n",
        "plt.ylabel('Hidden Neuron 2')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKNSfYaixevV"
      },
      "source": [
        "\n",
        "## Subtask 2\n",
        "\n",
        "Modify Subtask 1 so that you add three hidden layers and 2 latent features, i.e.\n",
        "784-10-2-10-784 neurons. Observe differences.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMHVdjwhxkxF"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "import random as rnd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the MNIST Fashion dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# Create a random subset of the dataset\n",
        "t_x = []\n",
        "t_y = []\n",
        "sz = len(train_images)\n",
        "for i in range(20):\n",
        "    idx = rnd.randint(0, sz - 1)\n",
        "    for c in range(10):\n",
        "        while train_labels[idx] != c:\n",
        "            idx = rnd.randint(0, sz - 1)\n",
        "        t_x.append(np.ndarray.flatten(train_images[idx]))\n",
        "        t_y.append(train_labels[idx])\n",
        "\n",
        "t_x = np.array(t_x, dtype=np.float32) / 255.0\n",
        "\n",
        "# Flatten the images\n",
        "t_x = t_x.reshape((len(t_x), np.prod(t_x.shape[1:])))\n",
        "\n",
        "# Define the autoencoder architecture with three hidden layers and 2 latent features\n",
        "input_img = Input(shape=(784,))\n",
        "hidden1 = Dense(10, activation='relu')(input_img)\n",
        "hidden2 = Dense(2, activation='relu')(hidden1)\n",
        "hidden3 = Dense(10, activation='relu')(hidden2)\n",
        "decoded = Dense(784, activation='sigmoid')(hidden3)\n",
        "\n",
        "# Create the autoencoder model\n",
        "autoencoder = Model(input_img, decoded)\n",
        "\n",
        "# Compile the autoencoder model\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Train the autoencoder\n",
        "autoencoder.fit(t_x, t_x, epochs=50, batch_size=4, shuffle=True)\n",
        "\n",
        "# Extract the responses of the hidden layer\n",
        "encoder_model = Model(inputs=input_img, outputs=hidden2)\n",
        "encoded_imgs = encoder_model.predict(t_x)\n",
        "\n",
        "# Plot the response of hidden neurons in a scatter plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "scatter = plt.scatter(encoded_imgs[:, 0], encoded_imgs[:, 1], c=t_y, cmap='tab10')\n",
        "plt.colorbar(scatter, label='Number Category')\n",
        "plt.title('Hidden Neuron Responses with 3 Hidden Layers')\n",
        "plt.xlabel('Hidden Neuron 1')\n",
        "plt.ylabel('Hidden Neuron 2')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXRS8WDQxrhi"
      },
      "source": [
        "## Subtask 3\n",
        "\n",
        "Modify Subtask 1 so that you add convolution layers, pooling layers, ... for the autoencoder and observe differences.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZwRdlqgx7Mi"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Input, Dense, Reshape, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from tensorflow.keras.models import Model\n",
        "import random as rnd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the MNIST Fashion dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# Create a random subset of the dataset\n",
        "t_x = []\n",
        "t_y = []\n",
        "sz = len(train_images)\n",
        "for i in range(20):\n",
        "    idx = rnd.randint(0, sz - 1)\n",
        "    for c in range(10):\n",
        "        while train_labels[idx] != c:\n",
        "            idx = rnd.randint(0, sz - 1)\n",
        "        t_x.append(train_images[idx])\n",
        "        t_y.append(train_labels[idx])\n",
        "\n",
        "t_x = np.array(t_x, dtype=np.float32) / 255.0\n",
        "\n",
        "# Add channel dimension to the images for convolutional layers\n",
        "t_x = np.expand_dims(t_x, axis=-1)\n",
        "\n",
        "# Define the convolutional autoencoder architecture\n",
        "input_img = Input(shape=(28, 28, 1))\n",
        "\n",
        "# Encoder\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "encoded = Conv2D(2, (3, 3), activation='relu', padding='same')(x)\n",
        "\n",
        "# Decoder\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "# Reshape to (28, 28) for visualization\n",
        "decoded_reshaped = Reshape((28, 28))(decoded)\n",
        "\n",
        "# Create the autoencoder model\n",
        "autoencoder = Model(input_img, decoded_reshaped)\n",
        "\n",
        "# Compile the autoencoder model\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Train the autoencoder\n",
        "autoencoder.fit(t_x, t_x, epochs=50, batch_size=4, shuffle=True)\n",
        "\n",
        "# Extract the responses of the encoded layer\n",
        "encoder_model = Model(inputs=input_img, outputs=encoded)\n",
        "encoded_imgs = encoder_model.predict(t_x)\n",
        "\n",
        "# Reshape the encoded data for scatter plot\n",
        "encoded_imgs_reshaped = encoded_imgs.reshape((len(encoded_imgs), -1))\n",
        "\n",
        "# Plot the response of hidden neurons in a scatter plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "scatter = plt.scatter(encoded_imgs_reshaped[:, 0], encoded_imgs_reshaped[:, 1], c=t_y, cmap='tab10')\n",
        "plt.colorbar(scatter, label='Number Category')\n",
        "plt.title('Encoded Layer Responses with Convolutional Autoencoder')\n",
        "plt.xlabel('Hidden Neuron 1')\n",
        "plt.ylabel('Hidden Neuron 2')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29wDJW-Yx9xD"
      },
      "source": [
        "\n",
        "## Subtask 4\n",
        "\n",
        "Extract the decoder from the autoencoder of subtask 1-3 and generate new images based on randomly generated latent features. Plot generated images.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5N5RytNyCdk"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Input, Dense, Reshape, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from tensorflow.keras.models import Model\n",
        "import random as rnd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the MNIST Fashion dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# Create a random subset of the dataset\n",
        "t_x = []\n",
        "t_y = []\n",
        "sz = len(train_images)\n",
        "for i in range(20):\n",
        "    idx = rnd.randint(0, sz - 1)\n",
        "    for c in range(10):\n",
        "        while train_labels[idx] != c:\n",
        "            idx = rnd.randint(0, sz - 1)\n",
        "        t_x.append(train_images[idx])\n",
        "        t_y.append(train_labels[idx])\n",
        "\n",
        "t_x = np.array(t_x, dtype=np.float32) / 255.0\n",
        "\n",
        "# Add channel dimension to the images for convolutional layers\n",
        "t_x = np.expand_dims(t_x, axis=-1)\n",
        "\n",
        "# Define the convolutional autoencoder architecture\n",
        "input_img = Input(shape=(28, 28, 1))\n",
        "\n",
        "# Encoder\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "encoded = Conv2D(2, (3, 3), activation='relu', padding='same')(x)\n",
        "\n",
        "# Decoder\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "# Reshape to (28, 28) for visualization\n",
        "decoded_reshaped = Reshape((28, 28))(decoded)\n",
        "\n",
        "# Create the autoencoder model\n",
        "autoencoder = Model(input_img, decoded_reshaped)\n",
        "\n",
        "# Compile the autoencoder model\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Train the autoencoder\n",
        "autoencoder.fit(t_x, t_x, epochs=50, batch_size=4, shuffle=True)\n",
        "\n",
        "# Extract the decoder part from the autoencoder\n",
        "decoder_input = Input(shape=(7, 7, 2))  # Adjust the shape based on the output shape of the encoder\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(decoder_input)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "# Reshape to (28, 28) for visualization\n",
        "decoded_reshaped = Reshape((28, 28))(decoded)\n",
        "\n",
        "# Create the decoder model\n",
        "decoder = Model(decoder_input, decoded_reshaped)\n",
        "\n",
        "# Generate new images based on randomly generated latent features\n",
        "num_generated_images = 10\n",
        "random_latent_features = np.random.rand(num_generated_images, 7, 7, 2)  # Adjust the shape based on the output shape of the encoder\n",
        "generated_images = decoder.predict(random_latent_features)\n",
        "\n",
        "# Reshape the generated images\n",
        "generated_images_reshaped = generated_images.reshape((num_generated_images, 28, 28))\n",
        "\n",
        "# Plot the generated images\n",
        "plt.figure(figsize=(15, 3))\n",
        "for i in range(num_generated_images):\n",
        "    plt.subplot(1, num_generated_images, i + 1)\n",
        "    plt.imshow(generated_images_reshaped[i], cmap='gray')\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.suptitle('Generated Images from Random Latent Features')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}